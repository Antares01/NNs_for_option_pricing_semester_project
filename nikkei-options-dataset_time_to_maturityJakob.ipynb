{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "nikkei-options-dataset_time_to_maturity.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Antares01/semester_project_ml_for_finance/blob/main/nikkei-options-dataset_time_to_maturityJakob.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2022-06-27T12:16:03.776668Z",
          "iopub.execute_input": "2022-06-27T12:16:03.777025Z",
          "iopub.status.idle": "2022-06-27T12:16:03.795293Z",
          "shell.execute_reply.started": "2022-06-27T12:16:03.776989Z",
          "shell.execute_reply": "2022-06-27T12:16:03.794119Z"
        },
        "trusted": true,
        "id": "coHTx_9ugGLi",
        "outputId": "c78ba3b1-f0e2-4f17-c8ed-e810ec635452"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/sample_submission.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/options.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/financials.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/secondary_stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/trades.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/jpx_tokyo_market_prediction/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/jpx_tokyo_market_prediction/__init__.py\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/stock_fin_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/trades_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/stock_price_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/options_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/stock_list_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/options.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/financials.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/secondary_stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/trades.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/options.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/financials.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/secondary_stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/trades.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from scipy.stats import lognorm\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.ndimage.filters import uniform_filter1d\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import date, datetime"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T12:16:06.560491Z",
          "iopub.execute_input": "2022-06-27T12:16:06.561451Z",
          "iopub.status.idle": "2022-06-27T12:16:07.601603Z",
          "shell.execute_reply.started": "2022-06-27T12:16:06.561407Z",
          "shell.execute_reply": "2022-06-27T12:16:07.600615Z"
        },
        "trusted": true,
        "id": "O4cCnR2WgGLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#integration parameter\n",
        "INTERVAL_LENGTH = 10\n",
        "START_UNIF = 0.01\n",
        "SCALING_CONSTANT = 10000"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T12:16:09.830012Z",
          "iopub.execute_input": "2022-06-27T12:16:09.830311Z",
          "iopub.status.idle": "2022-06-27T12:16:09.835191Z",
          "shell.execute_reply.started": "2022-06-27T12:16:09.830278Z",
          "shell.execute_reply": "2022-06-27T12:16:09.834210Z"
        },
        "trusted": true,
        "id": "DDLpbT2agGLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/options.csv\")\n",
        "print(options.columns)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T12:16:11.798402Z",
          "iopub.execute_input": "2022-06-27T12:16:11.798719Z",
          "iopub.status.idle": "2022-06-27T12:16:26.266507Z",
          "shell.execute_reply.started": "2022-06-27T12:16:11.798684Z",
          "shell.execute_reply": "2022-06-27T12:16:26.265369Z"
        },
        "trusted": true,
        "id": "eBdFxayUgGLn",
        "outputId": "f83f315d-b622-45b8-845c-c199dc5c8367"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3524: DtypeWarning: Columns (7,8,9,10) have mixed types.Specify dtype option on import or set low_memory=False.\n  exec(code_obj, self.user_global_ns, self.user_ns)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Index(['DateCode', 'Date', 'OptionsCode', 'WholeDayOpen', 'WholeDayHigh',\n       'WholeDayLow', 'WholeDayClose', 'NightSessionOpen', 'NightSessionHigh',\n       'NightSessionLow', 'NightSessionClose', 'DaySessionOpen',\n       'DaySessionHigh', 'DaySessionLow', 'DaySessionClose', 'TradingVolume',\n       'OpenInterest', 'TradingValue', 'ContractMonth', 'StrikePrice',\n       'WholeDayVolume', 'Putcall', 'LastTradingDay', 'SpecialQuotationDay',\n       'SettlementPrice', 'TheoreticalPrice', 'BaseVolatility',\n       'ImpliedVolatility', 'InterestRate', 'DividendRate', 'Dividend'],\n      dtype='object')\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T12:16:26.268823Z",
          "iopub.execute_input": "2022-06-27T12:16:26.269200Z",
          "iopub.status.idle": "2022-06-27T12:16:26.308126Z",
          "shell.execute_reply.started": "2022-06-27T12:16:26.269152Z",
          "shell.execute_reply": "2022-06-27T12:16:26.306965Z"
        },
        "trusted": true,
        "id": "45ERbFcrgGLn",
        "outputId": "e0636458-ab4f-4d00-e646-8f719903d405"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "             DateCode        Date  OptionsCode  WholeDayOpen  WholeDayHigh  \\\n0  20170104_132010018  2017-01-04    132010018         650.0         650.0   \n1  20170104_132010118  2017-01-04    132010118           0.0           0.0   \n2  20170104_132010218  2017-01-04    132010218           0.0           0.0   \n3  20170104_132010318  2017-01-04    132010318           0.0           0.0   \n4  20170104_132010518  2017-01-04    132010518           0.0           0.0   \n\n   WholeDayLow  WholeDayClose NightSessionOpen NightSessionHigh  \\\n0        480.0          480.0           0.0000           0.0000   \n1          0.0            0.0           0.0000           0.0000   \n2          0.0            0.0           0.0000           0.0000   \n3          0.0            0.0           0.0000           0.0000   \n4          0.0            0.0           0.0000           0.0000   \n\n  NightSessionLow  ... Putcall  LastTradingDay  SpecialQuotationDay  \\\n0          0.0000  ...       1        20170112             20170113   \n1          0.0000  ...       1        20170112             20170113   \n2          0.0000  ...       1        20170112             20170113   \n3          0.0000  ...       1        20170112             20170113   \n4          0.0000  ...       1        20170112             20170113   \n\n   SettlementPrice  TheoreticalPrice  BaseVolatility  ImpliedVolatility  \\\n0            480.0          478.4587         17.4736            17.5865   \n1            575.0          571.1385         17.4736            16.5000   \n2            680.0          677.3710         17.4736            15.8644   \n3            795.0          791.0383         17.4736            15.2288   \n4            910.0          909.9947         17.4736            14.5932   \n\n   InterestRate  DividendRate  Dividend  \n0        0.0091           0.0       0.0  \n1        0.0091           0.0       0.0  \n2        0.0091           0.0       0.0  \n3        0.0091           0.0       0.0  \n4        0.0091           0.0       0.0  \n\n[5 rows x 31 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DateCode</th>\n      <th>Date</th>\n      <th>OptionsCode</th>\n      <th>WholeDayOpen</th>\n      <th>WholeDayHigh</th>\n      <th>WholeDayLow</th>\n      <th>WholeDayClose</th>\n      <th>NightSessionOpen</th>\n      <th>NightSessionHigh</th>\n      <th>NightSessionLow</th>\n      <th>...</th>\n      <th>Putcall</th>\n      <th>LastTradingDay</th>\n      <th>SpecialQuotationDay</th>\n      <th>SettlementPrice</th>\n      <th>TheoreticalPrice</th>\n      <th>BaseVolatility</th>\n      <th>ImpliedVolatility</th>\n      <th>InterestRate</th>\n      <th>DividendRate</th>\n      <th>Dividend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20170104_132010018</td>\n      <td>2017-01-04</td>\n      <td>132010018</td>\n      <td>650.0</td>\n      <td>650.0</td>\n      <td>480.0</td>\n      <td>480.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>20170112</td>\n      <td>20170113</td>\n      <td>480.0</td>\n      <td>478.4587</td>\n      <td>17.4736</td>\n      <td>17.5865</td>\n      <td>0.0091</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20170104_132010118</td>\n      <td>2017-01-04</td>\n      <td>132010118</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>20170112</td>\n      <td>20170113</td>\n      <td>575.0</td>\n      <td>571.1385</td>\n      <td>17.4736</td>\n      <td>16.5000</td>\n      <td>0.0091</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20170104_132010218</td>\n      <td>2017-01-04</td>\n      <td>132010218</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>20170112</td>\n      <td>20170113</td>\n      <td>680.0</td>\n      <td>677.3710</td>\n      <td>17.4736</td>\n      <td>15.8644</td>\n      <td>0.0091</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20170104_132010318</td>\n      <td>2017-01-04</td>\n      <td>132010318</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>20170112</td>\n      <td>20170113</td>\n      <td>795.0</td>\n      <td>791.0383</td>\n      <td>17.4736</td>\n      <td>15.2288</td>\n      <td>0.0091</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20170104_132010518</td>\n      <td>2017-01-04</td>\n      <td>132010518</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>20170112</td>\n      <td>20170113</td>\n      <td>910.0</td>\n      <td>909.9947</td>\n      <td>17.4736</td>\n      <td>14.5932</td>\n      <td>0.0091</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options[['Date','LastTradingDay']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T12:16:26.309776Z",
          "iopub.execute_input": "2022-06-27T12:16:26.310690Z",
          "iopub.status.idle": "2022-06-27T12:16:26.361312Z",
          "shell.execute_reply.started": "2022-06-27T12:16:26.310633Z",
          "shell.execute_reply": "2022-06-27T12:16:26.360324Z"
        },
        "trusted": true,
        "id": "_hGlW99hgGLo",
        "outputId": "5331af7d-ed8e-43c4-b5b3-784b8c2a61d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "               Date  LastTradingDay\n0        2017-01-04        20170112\n1        2017-01-04        20170112\n2        2017-01-04        20170112\n3        2017-01-04        20170112\n4        2017-01-04        20170112\n...             ...             ...\n3567689  2021-12-03        20241212\n3567690  2021-12-03        20241212\n3567691  2021-12-03        20241212\n3567692  2021-12-03        20241212\n3567693  2021-12-03        20241212\n\n[3567694 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>LastTradingDay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-01-04</td>\n      <td>20170112</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-01-04</td>\n      <td>20170112</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-01-04</td>\n      <td>20170112</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-01-04</td>\n      <td>20170112</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-01-04</td>\n      <td>20170112</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3567689</th>\n      <td>2021-12-03</td>\n      <td>20241212</td>\n    </tr>\n    <tr>\n      <th>3567690</th>\n      <td>2021-12-03</td>\n      <td>20241212</td>\n    </tr>\n    <tr>\n      <th>3567691</th>\n      <td>2021-12-03</td>\n      <td>20241212</td>\n    </tr>\n    <tr>\n      <th>3567692</th>\n      <td>2021-12-03</td>\n      <td>20241212</td>\n    </tr>\n    <tr>\n      <th>3567693</th>\n      <td>2021-12-03</td>\n      <td>20241212</td>\n    </tr>\n  </tbody>\n</table>\n<p>3567694 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "option_expiry = 20170112\n",
        "trading_date = '2017-01-04'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T12:16:49.361279Z",
          "iopub.execute_input": "2022-06-27T12:16:49.361620Z",
          "iopub.status.idle": "2022-06-27T12:16:49.367110Z",
          "shell.execute_reply.started": "2022-06-27T12:16:49.361584Z",
          "shell.execute_reply": "2022-06-27T12:16:49.365855Z"
        },
        "trusted": true,
        "id": "raKu1WpXgGLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "dataset = options.loc[(options['LastTradingDay'] == option_expiry)& (options['WholeDayVolume']> 0) & (options['Date'] == trading_date)][['StrikePrice', 'Putcall', 'SettlementPrice']]#[['WholeDayClose', 'SettlementPrice']]\n",
        "dataset[['StrikePrice', 'SettlementPrice']] = dataset[['StrikePrice', 'SettlementPrice']].transform(lambda x : x/SCALING_CONSTANT)\n",
        "dataset['Putcall'] = dataset['Putcall'].transform(lambda x : False if x==1 else True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T12:16:51.565629Z",
          "iopub.execute_input": "2022-06-27T12:16:51.566317Z",
          "iopub.status.idle": "2022-06-27T12:16:52.064708Z",
          "shell.execute_reply.started": "2022-06-27T12:16:51.566277Z",
          "shell.execute_reply": "2022-06-27T12:16:52.063697Z"
        },
        "trusted": true,
        "id": "hpGQxDttgGLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = []\n",
        "for trading_date in tqdm(options['Date'].unique()):\n",
        "    dataset = options.loc[options['Date'] == trading_date]\n",
        "    for option_expiry in dataset['LastTradingDay'].unique():\n",
        "        dataset = dataset.loc[(options['LastTradingDay'] == option_expiry)& (options['WholeDayVolume']> 0)][['StrikePrice', 'Putcall', 'SettlementPrice']]#[['WholeDayClose', 'SettlementPrice']]\n",
        "        if dataset.empty:\n",
        "            continue\n",
        "\n",
        "        dataset[['StrikePrice', 'SettlementPrice']] = dataset[['StrikePrice', 'SettlementPrice']].transform(lambda x : x/SCALING_CONSTANT)\n",
        "        dataset['Putcall'] = dataset['Putcall'].transform(lambda x : False if x==1 else True)\n",
        "        trading_date = datetime.strptime(trading_date, '%Y-%m-%d')\n",
        "        option_expiry = datetime.strptime(str(option_expiry), '%Y%m%d')\n",
        "        ttm = option_expiry - trading_date\n",
        "        datasets.append((dataset, ttm.days))\n",
        "        \n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T12:57:33.008579Z",
          "iopub.execute_input": "2022-06-27T12:57:33.009506Z",
          "iopub.status.idle": "2022-06-27T13:11:21.904983Z",
          "shell.execute_reply.started": "2022-06-27T12:57:33.009452Z",
          "shell.execute_reply": "2022-06-27T13:11:21.903977Z"
        },
        "trusted": true,
        "id": "6hXYgdspgGLp",
        "outputId": "d1aa18b0-4150-442e-dcdf-f904771f85cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 1202/1202 [13:48<00:00,  1.45it/s]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Step 2\n",
        "with open('/kaggle/working/datasets.pkl', 'wb') as datasets_file:\n",
        " \n",
        "  # Step 3\n",
        "  pickle.dump(datasets, datasets_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T13:11:58.673612Z",
          "iopub.execute_input": "2022-06-27T13:11:58.673935Z",
          "iopub.status.idle": "2022-06-27T13:11:58.712889Z",
          "shell.execute_reply.started": "2022-06-27T13:11:58.673900Z",
          "shell.execute_reply": "2022-06-27T13:11:58.711783Z"
        },
        "trusted": true,
        "id": "3A0WCgA4gGLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/kaggle/working/datasets.pkl', 'rb') as datasets_file:\n",
        "    datasets_copy = pickle.load(datasets_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T13:12:11.997934Z",
          "iopub.execute_input": "2022-06-27T13:12:11.998244Z",
          "iopub.status.idle": "2022-06-27T13:12:12.084154Z",
          "shell.execute_reply.started": "2022-06-27T13:12:11.998209Z",
          "shell.execute_reply": "2022-06-27T13:12:12.083041Z"
        },
        "trusted": true,
        "id": "48BtEruxgGLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(datasets_copy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-06-27T13:12:37.197668Z",
          "iopub.execute_input": "2022-06-27T13:12:37.197997Z",
          "iopub.status.idle": "2022-06-27T13:12:37.204680Z",
          "shell.execute_reply.started": "2022-06-27T13:12:37.197964Z",
          "shell.execute_reply": "2022-06-27T13:12:37.203721Z"
        },
        "trusted": true,
        "id": "rKuI0BS5gGLq",
        "outputId": "3e494989-01dc-4967-c986-7d61b51f3132"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "378"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(dataset, test_size = 0.2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ldJY9qeAgGLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(datasets)"
      ],
      "metadata": {
        "trusted": true,
        "id": "q44vsozagGLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "lzxO5nD2gGLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['StrikePrice'].iloc[1]"
      ],
      "metadata": {
        "trusted": true,
        "id": "3y62L9kCgGLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "prices_and_strikes = [ (train_df['SettlementPrice'].iloc[i], train_df['StrikePrice'].iloc[i], train_df['Putcall'].iloc[i]) for i in range(len(train_df))]\n",
        "train_set_size = len(prices_and_strikes)\n",
        "batch_size = 16\n",
        "target_dataloader = DataLoader(prices_and_strikes , batch_size=batch_size, shuffle = True)\n",
        "#test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "trusted": true,
        "id": "OVkpGgkWgGLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prices_and_strikes = [ (test_df['SettlementPrice'].iloc[i], test_df['StrikePrice'].iloc[i], test_df['Putcall'].iloc[i]) for i in range(len(test_df))]\n",
        "test_set_size = len(test_prices_and_strikes)\n",
        "batch_size = len(test_prices_and_strikes)\n",
        "test_dataloader = DataLoader(test_prices_and_strikes , batch_size=batch_size, shuffle = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "EkZtsj88gGLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaselineNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(2, 128),\n",
        "            nn.LeakyReLU(1e-1),\n",
        "            \n",
        "            nn.Linear(128, 512),\n",
        "            nn.LeakyReLU(1e-1),   \n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.LeakyReLU(1e-1),\n",
        "            \n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "        self.softplus = nn.Softplus()\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        y = torch.log(x)\n",
        "        x = self.linear_relu_stack(torch.cat((x,y), 1))\n",
        "        x = self.softplus(x)\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "id": "cTlxBV6FgGLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeEncodingNet(nn.Module):\n",
        "    def __init__(out_size, self):\n",
        "        self.out_size = out_size\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(1, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, out_size)\n",
        "        )\n",
        "        \n",
        "    def forward(self, ttm):\n",
        "        return self.mlp(ttm)"
      ],
      "metadata": {
        "trusted": true,
        "id": "QTLMJSjngGLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedNet(nn.Module):\n",
        "    def __init__(time_encoding_net, self):\n",
        "        super(BaselineNet, self).__init__()\n",
        "        self.time_encoding_net = time_encoding_net\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(2, 128),\n",
        "            nn.LeakyReLU(1e-1),\n",
        "            \n",
        "            nn.Linear(128, 512),\n",
        "            nn.LeakyReLU(1e-1),   \n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.LeakyReLU(1e-1),\n",
        "            \n",
        "            nn.Linear(128, self.time_encoding_net.out_size)\n",
        "        )\n",
        "        self.common_head = nn.Sequential(\n",
        "            nn.Linear(2*self.time_encoding_net.out_size, 64),\n",
        "            nn.LeakyReLU(1e-1),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "        self.softplus = nn.Softplus()\n",
        "        \n",
        "        \n",
        "    def forward(self, x, ttm):\n",
        "        x = self.flatten(x)\n",
        "        y = torch.log(x)\n",
        "        x = self.linear_relu_stack(torch.cat((x,y), 1))\n",
        "        x = torch.cat((x, self.time_encoding_net(ttm)), 1)\n",
        "        x = self.common_head(x)\n",
        "        x = self.softplus(x)\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "id": "8DLSWOjHgGLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "#model = BaselineNet().to(device)\n",
        "model_eq = BaselineNet().to(device)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "W2f0FEAsgGLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OptionLoss(nn.Module):\n",
        "    def __init__(self, beta):\n",
        "        super(OptionLoss,self).__init__()\n",
        "        self.beta = beta\n",
        "    \n",
        "    # outputs the MC_STEPS predictions, labels the TOT_OPTIONS labels\n",
        "    def forward(self, outputs, labels, strike, is_call, coordinates):\n",
        "        mc_steps = len(coordinates)\n",
        "        loss = 0\n",
        "        mc_integral = 0\n",
        "        payoff = lambda  j :  torch.max(torch.zeros(len(outputs)), coordinates - strike[j] ) if is_call[j] else torch.max(torch.zeros(len(outputs)), strike[j] - coordinates)\n",
        "        #densities_ratio = torch.div(outputs , torch.Tensor([lognorm.pdf(coordinates, PROPOSAL_SIGMA, 0, np.exp(PROPOSAL_MU)) ]))\n",
        "        #print(outputs)\n",
        "        densities = 1/INTERVAL_LENGTH #torch.Tensor([lognorm.pdf(coordinates, PROPOSAL_SIGMA, 0, np.exp(PROPOSAL_MU)) ])\n",
        "        #print(densities_ratio)\n",
        "        for j in range(len(labels)):\n",
        "          mc_price = payoff(j) * outputs / densities\n",
        "          loss += (labels[j] -  mc_price.sum() / mc_steps)**2\n",
        "\n",
        "        return loss  #+ self.beta * (1 - 0.5*mc_integral)**2\n",
        "            \n"
      ],
      "metadata": {
        "trusted": true,
        "id": "zi33-pxogGLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AbsolutePercentageLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AbsolutePercentageLoss, self).__init__()\n",
        "    \n",
        "    # outputs the MC_STEPS predictions, labels the TOT_OPTIONS labels\n",
        "    def forward(self, outputs, labels, strike, is_call, coordinates):\n",
        "        mc_steps = len(coordinates)\n",
        "        loss = 0\n",
        "        mc_integral = 0\n",
        "        payoff = lambda  j :  torch.max(torch.zeros(len(outputs)), coordinates - strike[j] ) if is_call[j] else torch.max(torch.zeros(len(outputs)), strike[j] - coordinates)\n",
        "        densities = 1/INTERVAL_LENGTH \n",
        "        for j in range(len(labels)):\n",
        "          mc_price = payoff(j) * outputs / densities\n",
        "          loss += torch.abs(labels[j] -  mc_price.sum() / mc_steps)/labels[j]\n",
        "\n",
        "        return loss  \n",
        "            \n"
      ],
      "metadata": {
        "trusted": true,
        "id": "LToi_2f0gGLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-20)\n",
        "optimizer_eq = torch.optim.Adam(model_eq.parameters(), lr=1e-4, weight_decay=1e-20)\n",
        "loss_fn = OptionLoss(0)\n",
        "test_error = AbsolutePercentageLoss()"
      ],
      "metadata": {
        "trusted": true,
        "id": "dVazHuh1gGLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_encoding_net = TimeEncodingNet(64)\n",
        "improved_model = ImprovedNet(time_encoding_net)\n",
        "optimizer_whole_network = torch.optim.Adam(improved_model.parameters(), lr=1e-4, weight_decay=1e-20)"
      ],
      "metadata": {
        "id": "HYeDLVahgGLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_improved_model(input_model, optimizer, loss_fn, C1, C2, target_dataloader, equidistant_window=False):\n",
        "    loss_history = []\n",
        "    for epoch in tqdm(range(int(600*C1))):\n",
        "        avg_loss = 0\n",
        "        for batch, (target_prices, strike_prices, is_call) in enumerate(target_dataloader):\n",
        "            if epoch < 100 * C1:\n",
        "                mc_steps = int(128*C2)\n",
        "            elif epoch < 200 * C1:\n",
        "                mc_steps = int(256*C2)\n",
        "            elif epoch < 250 * C1:\n",
        "                mc_steps = int(512*C2)\n",
        "            elif epoch < 275 * C1:\n",
        "                mc_steps = int(1024*C2)\n",
        "            elif epoch < 287 * C1:\n",
        "                mc_steps = int(2048*C2)\n",
        "            elif epoch < 293*C1:\n",
        "                mc_steps = int(4096*C2)\n",
        "            else:\n",
        "                mc_steps = int(8192*C2)\n",
        "            \n",
        "            \n",
        "            if equidistant_window:\n",
        "                coordinates=np.linspace(start=START_UNIF+INTERVAL_LENGTH/(2*mc_steps),stop=START_UNIF+INTERVAL_LENGTH-INTERVAL_LENGTH/(2*mc_steps),num=mc_steps)+np.random.uniform(low=-INTERVAL_LENGTH/(2*mc_steps),high=INTERVAL_LENGTH/(2*mc_steps),size=mc_steps)\n",
        "                coordinates = coordinates.reshape(  -1, 1)\n",
        "                X = torch.tensor(coordinates, dtype = torch.float32).to(device)\n",
        "                \n",
        "\n",
        "            else:\n",
        "                X = torch.zeros(mc_steps, 1).to(device)\n",
        "                X.uniform_(START_UNIF, INTERVAL_LENGTH)\n",
        "\n",
        "\n",
        "\n",
        "            #print(X)\n",
        "            #X.log_normal_(PROPOSAL_MU, PROPOSAL_SIGMA )\n",
        "            #print(X)\n",
        "            pred = input_model(X)\n",
        "            loss = loss_fn(pred.cpu().squeeze(), target_prices, strike_prices, is_call, X.cpu().squeeze())\n",
        "            \n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(input_model.parameters(), 1e-1)\n",
        "            optimizer.step()\n",
        "            avg_loss += loss\n",
        "        loss_history.append(float(avg_loss/batch))\n",
        "    return loss_history"
      ],
      "metadata": {
        "id": "S0i0LsqzgGLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_model, optimizer, loss_fn, C1, C2, target_dataloader, equidistant_window=False):\n",
        "    loss_history = []\n",
        "    for epoch in tqdm(range(int(296*C1))):\n",
        "        avg_loss = 0\n",
        "        for batch, (target_prices, strike_prices, is_call) in enumerate(target_dataloader):\n",
        "            if epoch < 100 * C1:\n",
        "                mc_steps = int(128*C2)\n",
        "            elif epoch < 200 * C1:\n",
        "                mc_steps = int(256*C2)\n",
        "            elif epoch < 250 * C1:\n",
        "                mc_steps = int(512*C2)\n",
        "            elif epoch < 275 * C1:\n",
        "                mc_steps = int(1024*C2)\n",
        "            elif epoch < 287 * C1:\n",
        "                mc_steps = int(2048*C2)\n",
        "            elif epoch < 293*C1:\n",
        "                mc_steps = int(4096*C2)\n",
        "            else:\n",
        "                mc_steps = int(8192*C2)\n",
        "            \n",
        "            \n",
        "            if equidistant_window:\n",
        "                coordinates=np.linspace(start=START_UNIF+INTERVAL_LENGTH/(2*mc_steps),stop=START_UNIF+INTERVAL_LENGTH-INTERVAL_LENGTH/(2*mc_steps),num=mc_steps)+np.random.uniform(low=-INTERVAL_LENGTH/(2*mc_steps),high=INTERVAL_LENGTH/(2*mc_steps),size=mc_steps)\n",
        "                coordinates = coordinates.reshape(  -1, 1)\n",
        "                X = torch.tensor(coordinates, dtype = torch.float32).to(device)\n",
        "                \n",
        "\n",
        "            else:\n",
        "                X = torch.zeros(mc_steps, 1).to(device)\n",
        "                X.uniform_(START_UNIF, INTERVAL_LENGTH)\n",
        "\n",
        "\n",
        "\n",
        "            #print(X)\n",
        "            #X.log_normal_(PROPOSAL_MU, PROPOSAL_SIGMA )\n",
        "            #print(X)\n",
        "            pred = input_model(X)\n",
        "            loss = loss_fn(pred.cpu().squeeze(), target_prices, strike_prices, is_call, X.cpu().squeeze())\n",
        "            \n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(input_model.parameters(), 1e-1)\n",
        "            optimizer.step()\n",
        "            avg_loss += loss\n",
        "        loss_history.append(float(avg_loss/batch))\n",
        "    return loss_history"
      ],
      "metadata": {
        "trusted": true,
        "id": "BD8KFd7xgGLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, loss_fn, test_dataloader, mc_steps = 4096):\n",
        "    # only one single batch used\n",
        "    for batch, (target_prices, strike_prices, is_call) in enumerate(test_dataloader):\n",
        "        coordinates=np.linspace(start=START_UNIF+INTERVAL_LENGTH/(2*mc_steps),stop=START_UNIF+INTERVAL_LENGTH-INTERVAL_LENGTH/(2*mc_steps),num=mc_steps)+np.random.uniform(low=-INTERVAL_LENGTH/(2*mc_steps),high=INTERVAL_LENGTH/(2*mc_steps),size=mc_steps)\n",
        "        coordinates = coordinates.reshape(  -1, 1)\n",
        "        X = torch.tensor(coordinates, dtype = torch.float32).to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred.cpu().squeeze(), target_prices, strike_prices, is_call, X.cpu().squeeze())\n",
        "    return loss/len(test_dataloader)\n",
        "        "
      ],
      "metadata": {
        "trusted": true,
        "id": "UtDvyLCbgGLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss_history = train(model, optimizer, loss_fn, 2, 1, target_dataloader, equidistant_window = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "MvkITl_9gGLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history_eq = train(model_eq, optimizer_eq, loss_fn, 3, 1.5, target_dataloader, equidistant_window = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ULPi46ikgGLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "x = torch.Tensor(np.arange(0.1, 4 , 0.01)).to(device).unsqueeze(-1)\n",
        "p = model(x) \n",
        "plt.plot(x.cpu().detach().numpy() * SCALING_CONSTANT, p.cpu().detach().numpy() / SCALING_CONSTANT)\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "id": "jc10I-rigGLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(np.arange(0.1, 4 , 0.01)).to(device).unsqueeze(-1)\n",
        "p_eq = model_eq(x)\n",
        "plt.plot(x.cpu().detach().numpy() * SCALING_CONSTANT, p_eq.cpu().detach().numpy() / SCALING_CONSTANT)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0aF-L6N1gGLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.plot(range(len(loss_history)), loss_history)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9iY7wXTWgGLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(loss_history_eq)), loss_history_eq)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ojmT8PBggGLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "running_loss_average = uniform_filter1d(loss_history, size=50)\n",
        "plt.plot(range(len(running_loss_average[-300:])), running_loss_average[-300:])\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "id": "E5pfrGuLgGLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss_average_eq = uniform_filter1d(loss_history_eq, size=50)\n",
        "plt.plot(range(len(running_loss_average_eq[-200:])), running_loss_average_eq[-200:])"
      ],
      "metadata": {
        "trusted": true,
        "id": "tbj5SonigGLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_error = test(model_eq, test_error, test_dataloader)\n",
        "average_error = total_error.detach().numpy() / len(test_prices_and_strikes)\n",
        "print(average_error)\n",
        "print(len(test_prices_and_strikes))"
      ],
      "metadata": {
        "trusted": true,
        "id": "5m4duJEjgGLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(np.arange(0.001, 20, 0.01)).to(device).unsqueeze(-1)\n",
        "p = np.array(model(x).detach())\n",
        "print(np.argmax(p)*0.01*SCALING_CONSTANT)"
      ],
      "metadata": {
        "trusted": true,
        "id": "yo8TdIo8gGLw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}